{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三章：决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.1 信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算给定数据集的香农熵\n",
    "# 输入：一个数据集\n",
    "# 返回：这个数据集的香农熵\n",
    "\n",
    "from math import log\n",
    "\n",
    "def calcShannonEntropy(dataSet):\n",
    "    numEntries = len(dataSet) # 获取数据集长度\n",
    "    labelCounts = {} #用于存储 labels 个数的字典\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        # 如果当前的label不在labelCounts中， 则创建这个元素\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "        shannonEntropy = 0.0\n",
    "        for key in labelCounts:\n",
    "            prob = float ( labelCounts[key] )/numEntries # 计算这个label出现的概率\n",
    "            shannonEntropy = shannonEntropy - prob * log(prob, 2) # 计算熵并叠加\n",
    "    return shannonEntropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# createDataSet: 创建一个数据集\n",
    "# 返回：一个数据集和标签\n",
    "\n",
    "def createDataSet():\n",
    "    dataSet = [\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no']\n",
    "    ]\n",
    "    labels = [ 'no surfacing', 'flippers']\n",
    "    return dataSet, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEntropy(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加一个类别查看熵的变化\n",
    "myDat[0][-1] = 'maybe'\n",
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看熵的变化， 可见：混合的数据越多， 熵越高\n",
    "calcShannonEntropy(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 按照给定特征划分数据集， 将  dataSet 中的符合 axis 特征值等于 value 的这些样本抽取出来\n",
    "# 输入：dataSet(待划分的数据集)，axis（用来划分数据集的特征），value（匹配的特征的值）\n",
    "# 输出：符合 axis 特征值等于 value 的样本组成的一个新的数据集\n",
    "\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    returnDataSet = []\n",
    "    \n",
    "    # 对数据集中的每个样本进行遍历\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value: # 如果符合条件的样本则加入到返回的returnDataSet中\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            returnDataSet.append(reducedFeatVec)\n",
    "    return returnDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [4, 5, 6]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append 和 extend 在处理多个列表时处理结果是不同的\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "a.append(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "a.extend(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(myDat, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataSet = myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range( len(dataSet[0]) -1  ):\n",
    "    featList = [ example[i] for example in dataSet ] # 获取dataSet中所有样本的第 i 个特征值的所有出现的值, 用于后面计算熵\n",
    "featList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueVals = set(featList)\n",
    "uniqueVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择最好的数据集划分方式\n",
    "# 输入：一个数据集\n",
    "# 输出： 最好特征划分的索引值\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len( dataSet[0] ) - 1 # 获取特征个数\n",
    "    baseEntropy = calcShannonEntropy(dataSet) # 最初的数据集的熵\n",
    "    bestInfoGain = 0.0; bestFeature = -1;\n",
    "    for i in range(numFeatures): # 遍历数据集中的每个特征\n",
    "        featList = [ example[i] for example in dataSet ] # 获取dataSet中所有样本的第 i 个特征值的所有出现的值, 用于后面计算熵\n",
    "        uniqueVals = set(featList) # 将featList 中出现的值放入一个集合中， 不会重复放入\n",
    "        newEntropy = 0.0\n",
    "        # 计算用这个特征划分数据得到的新的 熵\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEntropy(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy # 数据集变得更加有序是熵减的过程， 熵减得越多， 则用这个数据划分数据集会更好\n",
    "        if( infoGain >  bestInfoGain): # 如果用当前这个特征划分数据后， 数据集比 之前最好的特征划分的数据集 更加有序， 则进行更新\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDat, labels = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(myDat) # 结果表明第 0 个特征是最好的用于划分数据集的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 递归构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 该函数使用分类名称的列表， 并返回出现次数最多的分类名称\n",
    "# 输入： 分类名称的列表\n",
    "#输出： 出现次数最多的分类名称\n",
    "\n",
    "import operator\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classLsit:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "    classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key = operator.itemgetter(1), reverse = True)\n",
    "    return  sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDat, labels = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateSet = myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maybe', 'yes', 'no', 'no', 'no']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classList = [ example[-1] for example in dataSet ] #获取所有的 分类名称\n",
    "classList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestFeature = chooseBestFeatureToSplit(dataSet) # 选择最好的数据集划分方式 的 特征\n",
    "bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no surfacing'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestFeatureLabel = labels[bestFeature]\n",
    "bestFeatureLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree = {bestFeatureLabel:{}}\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(labels[bestFeature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flippers']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureValues = [ example[bestFeature] for example in dataSet ] # 获取数据集中所有样本该特征的值\n",
    "featureValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueValues = set(featureValues) # 将featureValues 中出现的值放入一个集合中， 不会重复放入\n",
    "uniqueValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 运用递归创建决策树\n",
    "# 输入： dataSet：数据集， Labels: 特征标签列表\n",
    "# 返回：用字典的字典存储的决策树\n",
    "\n",
    "def createTree(dataSet, Labels):\n",
    "    classList = [ example[-1] for example in dataSet ] #获取所有的 分类名称\n",
    "    \n",
    "    if classList.count(classList[0]) == len(classList): #如果剩下的样本全部属于同一类， 则停止继续划分， 直接返回该类\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1: # 如果此时只剩下一个特征， 则停止继续划分， 直接返回剩余样本中占比数最大的类别\n",
    "        return majorityCnt(classList)\n",
    "    \n",
    "    # 得到最好的划分数据集的特征\n",
    "    bestFeature = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatureLabel = labels[bestFeature] \n",
    "    \n",
    "    myTree = {bestFeatureLabel:{}}\n",
    "    del(labels[bestFeature]) # 删除labels中已经使用过的特征\n",
    "    featureValues = [ example[bestFeature] for example in dataSet ] # 获取数据集中所有样本该特征的值\n",
    "    uniqueValues = set(featureValues) # 将featureValues 中出现的值放入一个集合中， 不会重复放入\n",
    "    \n",
    "    # myTree是一个字典的字典，在使用　bestFeatureLabel　进行划分数据集时，将值为　value　的数据集找出来，　用subLabels　再次调用本身函数\n",
    "    # 则能够返回一棵 tree ，那么这棵 trre 就是 myTree 在在使用　bestFeatureLabel　进行划分数据集时，值为value时 字典对应的值\n",
    "    for value in uniqueValues:\n",
    "        subLabels = labels[:] # 剩余的可以用于划分数据的特征\n",
    "        myTree[bestFeatureLabel][value] = createTree( splitDataSet(dataSet, bestFeature, value),subLabels)\n",
    "    \n",
    "    return myTree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试以上函数\n",
    "myDat, labels = createDataSet()\n",
    "myTree = createTree(myDat, labels)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
